{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fraud Detection Baseline (Google Colab)\n",
        "\n",
        "This notebook trains a low-memory baseline model for card transaction fraud detection using the `creditcard.csv` dataset.\n",
        "\n",
        "Outputs:\n",
        "- PR-AUC\n",
        "- ROC-AUC\n",
        "- Recall at fixed FPR (default 2%)\n",
        "- Suggested thresholds for `approve / review / decline`\n",
        "- Saved model artifact (`baseline_logreg.joblib`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "!pip -q install numpy pandas scikit-learn matplotlib joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Load dataset\n",
        "Use one of these options:\n",
        "- Upload `creditcard.csv` directly from your machine\n",
        "- Point `DATA_PATH` to a file in Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dataset_path"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "UPLOAD_FROM_BROWSER = True\n",
        "\n",
        "if UPLOAD_FROM_BROWSER:\n",
        "    try:\n",
        "        from google.colab import files\n",
        "    except ImportError:\n",
        "        raise RuntimeError('Run this notebook in Google Colab or set UPLOAD_FROM_BROWSER=False and DATA_PATH manually.')\n",
        "\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        raise ValueError('No file uploaded. Upload creditcard.csv to continue.')\n",
        "    DATA_PATH = next(iter(uploaded.keys()))\n",
        "else:\n",
        "    # Example: /content/drive/MyDrive/Fraud-ML/data/creditcard.csv\n",
        "    DATA_PATH = '/content/drive/MyDrive/Fraud-ML/data/creditcard.csv'\n",
        "\n",
        "print('DATA_PATH =', DATA_PATH)\n",
        "assert Path(DATA_PATH).exists(), f'File not found: {DATA_PATH}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Data contract + helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_contract"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score, roc_curve\n",
        "import joblib\n",
        "\n",
        "LABEL_COLUMN = 'Class'\n",
        "TIME_COLUMN = 'Time'\n",
        "REQUIRED_COLUMNS = {TIME_COLUMN, 'Amount', LABEL_COLUMN, *{f'V{i}' for i in range(1, 29)}}\n",
        "LEAKAGE_COLUMNS = {LABEL_COLUMN}\n",
        "\n",
        "def validate_dataframe(df: pd.DataFrame, require_label: bool = True) -> None:\n",
        "    required = set(REQUIRED_COLUMNS)\n",
        "    if not require_label:\n",
        "        required.discard(LABEL_COLUMN)\n",
        "    missing = sorted(required - set(df.columns))\n",
        "    if missing:\n",
        "        raise ValueError(f'Missing required columns: {missing}')\n",
        "\n",
        "def feature_columns(columns):\n",
        "    return sorted([c for c in columns if c not in LEAKAGE_COLUMNS])\n",
        "\n",
        "def recall_at_fpr(y_true: np.ndarray, y_score: np.ndarray, target_fpr: float = 0.02):\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
        "    valid = np.where(fpr <= target_fpr)[0]\n",
        "    if len(valid) == 0:\n",
        "        return 0.0, 1.0\n",
        "    i = valid[-1]\n",
        "    return float(tpr[i]), float(thresholds[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Read and prepare data (memory-efficient)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prepare_data"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(DATA_PATH)\n",
        "validate_dataframe(df, require_label=True)\n",
        "\n",
        "float_cols = [c for c in df.columns if c != LABEL_COLUMN]\n",
        "df[float_cols] = df[float_cols].astype(np.float32)\n",
        "df[LABEL_COLUMN] = df[LABEL_COLUMN].astype(np.int8)\n",
        "\n",
        "# Temporal split: train on past, test on future-like slice\n",
        "df = df.sort_values(TIME_COLUMN)\n",
        "split_idx = int(len(df) * 0.8)\n",
        "train_df = df.iloc[:split_idx].copy()\n",
        "test_df = df.iloc[split_idx:].copy()\n",
        "\n",
        "X_cols = feature_columns(train_df.columns)\n",
        "X_train = train_df[X_cols].to_numpy(dtype=np.float32)\n",
        "y_train = train_df[LABEL_COLUMN].to_numpy(dtype=np.int8)\n",
        "X_test = test_df[X_cols].to_numpy(dtype=np.float32)\n",
        "y_test = test_df[LABEL_COLUMN].to_numpy(dtype=np.int8)\n",
        "\n",
        "print('Train shape:', X_train.shape, 'Fraud rate:', y_train.mean())\n",
        "print('Test shape :', X_test.shape, 'Fraud rate:', y_test.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Train baseline model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_model"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(class_weight='balanced', max_iter=500, n_jobs=-1)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_score = model.predict_proba(X_test)[:, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Evaluate metrics and choose threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evaluate"
      },
      "outputs": [],
      "source": [
        "TARGET_FPR = 0.02\n",
        "\n",
        "pr_auc = average_precision_score(y_test, y_score)\n",
        "roc_auc = roc_auc_score(y_test, y_score)\n",
        "recall, threshold = recall_at_fpr(y_test, y_score, target_fpr=TARGET_FPR)\n",
        "\n",
        "print('=== Baseline Metrics ===')\n",
        "print(f'PR-AUC: {pr_auc:.6f}')\n",
        "print(f'ROC-AUC: {roc_auc:.6f}')\n",
        "print(f'Recall @ FPR <= {TARGET_FPR:.2%}: {recall:.6f}')\n",
        "print(f'Threshold for target FPR: {threshold:.6f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "policy_thresholds"
      },
      "outputs": [],
      "source": [
        "# Draft 3-band policy based on model score distribution\n",
        "T1 = float(np.quantile(y_score, 0.90))  # review threshold\n",
        "T2 = float(threshold)                   # decline threshold from FPR target\n",
        "\n",
        "print('Suggested policy thresholds:')\n",
        "print(f'approve: score < {T1:.6f}')\n",
        "print(f'review : {T1:.6f} <= score < {T2:.6f}')\n",
        "print(f'decline: score >= {T2:.6f}')\n",
        "\n",
        "if T1 > T2:\n",
        "    print('Note: T1 > T2 with this distribution. Set T1 manually below T2 after reviewing score histogram.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Save artifact"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save_model"
      },
      "outputs": [],
      "source": [
        "artifact = {\n",
        "    'model': model,\n",
        "    'feature_columns': X_cols,\n",
        "    'threshold_for_target_fpr': float(threshold),\n",
        "    'target_fpr': float(TARGET_FPR),\n",
        "}\n",
        "joblib.dump(artifact, 'baseline_logreg.joblib')\n",
        "print('Saved: baseline_logreg.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next step\n",
        "Integrate this artifact into a FastAPI `/predict` endpoint, then serve with Gunicorn + Uvicorn workers."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "fraud_baseline_colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
